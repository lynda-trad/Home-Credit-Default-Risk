{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926cff61",
   "metadata": {},
   "source": [
    "# Home Credit Default Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce08ba",
   "metadata": {},
   "source": [
    "We have a dataframe in which are registered a lot of information about a bank's clients.\n",
    "\n",
    "The bank wants to know if they should give them a loan or not. The machine learning model needs to predict if the client will repay the loan or not.\n",
    "\n",
    "If the target is equal to 0: the loan was repaid, if it's equal to 1: the loan was not repaid.\n",
    "\n",
    "The models will determine if the loan will be repaid or not according to the given features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e561c9be",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e104a7e2",
   "metadata": {},
   "source": [
    "* Data observation\n",
    "* Data cleanup\n",
    "* Boruta \n",
    "\n",
    "Machine Learning Models: \n",
    "* KNeighbors Classifier using Grid Search\n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* XGBoost\n",
    "\n",
    "* Comparing models predictions on application test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10a254",
   "metadata": {},
   "source": [
    "# Library used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import graphviz\n",
    "\n",
    "# Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Machine Learning Library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Grid Search\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Boruta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import BorutaPy as bp\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01fa184",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83575876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_train = pd.read_csv(\"./resources/application_train.csv\", encoding='utf-8', sep=',')\n",
    "app_test = pd.read_csv(\"./resources/application_test.csv\", encoding='utf-8', sep=',')\n",
    "app_train.drop_duplicates()\n",
    "app_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47ad3b",
   "metadata": {},
   "source": [
    "## Aligning the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab2ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "app_train['TARGET'] = train_labels\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73cd42",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457fb1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3f699",
   "metadata": {},
   "source": [
    "## Is data unbalanced ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f995c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.countplot(x=\"TARGET\", data=app_train)\n",
    "plt.title('Balance of target')\n",
    "plt.show()\n",
    "print(\"Unbalanced data on the TARGET column:\")\n",
    "print(app_train['TARGET'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9040755",
   "metadata": {},
   "source": [
    "The data is very unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d5e23",
   "metadata": {},
   "source": [
    "## Gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group = app_train.groupby(['CODE_GENDER'])\n",
    "gender_group.size().plot(kind='pie', \n",
    "                         ylabel='Gender', \n",
    "                         colors=['pink', 'steelblue', 'pink'], \n",
    "                         title='Gender distribution',\n",
    "                         autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a01a8",
   "metadata": {},
   "source": [
    "### Contract type distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca938d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_group = app_train.groupby(['NAME_CONTRACT_TYPE'])\n",
    "contract_group.size().plot(kind='pie', \n",
    "                           ylabel='', \n",
    "                           colors=['green', 'steelblue'], \n",
    "                           title='Contract type distribution',\n",
    "                           autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876969f",
   "metadata": {},
   "source": [
    "## Days Birth feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc54fd",
   "metadata": {},
   "source": [
    "### Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "(app_train['DAYS_BIRTH'] / -365).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0593cb",
   "metadata": {},
   "source": [
    "### Minimum and maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = abs(app_train['DAYS_BIRTH'].max())\n",
    "if mini > 365:\n",
    "    print(\"Days birth min :\", mini/365, \"days\" )\n",
    "else:\n",
    "    print(\"Days birth min :\", mini, \"days\" )\n",
    "    \n",
    "maxi = abs(app_train['DAYS_BIRTH'].min())\n",
    "print(\"Days birth max :\", maxi/365, \"years\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71653bbd",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0eb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=abs(app_train['DAYS_BIRTH']))\n",
    "plt.title('Boxplot of Days Birth before cleaning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cfd95e",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01297194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"30 first columns filled with the most NaN values with their percentage:\")\n",
    "((app_train.isnull().sum()/app_train.shape[0])*100).sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b3cf1",
   "metadata": {},
   "source": [
    "# Data cleanup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c82536b",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698acab3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object' or app_train[col].dtype == 'string':\n",
    "        le.fit(app_train[col])\n",
    "        app_train[col] = le.transform(app_train[col])\n",
    "        app_test[col] = le.transform(app_test[col])\n",
    "        le_count += 1\n",
    "        print(col)\n",
    "app_train.reset_index()\n",
    "app_test.reset_index()\n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae495b84",
   "metadata": {},
   "source": [
    "## Missing and infinite values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e181bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replacing Infinite values with NaN values\n",
    "app_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "app_test.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\").fit(app_train)\n",
    "imputer = imputer.fit_transform(app_train)\n",
    "app_train = pd.DataFrame(imputer, columns = app_train.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae26ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\").fit(app_test)\n",
    "imputer = imputer.fit_transform(app_test)\n",
    "app_test = pd.DataFrame(imputer, columns = app_test.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd8f51",
   "metadata": {},
   "source": [
    "## Handling unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "X = app_train\n",
    "Y = np.array(app_train['TARGET'])\n",
    "X.drop('TARGET', axis=1, inplace=True)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "app_train, y_resampled = rus.fit_resample(X,Y)\n",
    "app_train['TARGET'] = y_resampled\n",
    "print(sorted(Counter(y_resampled).items()), y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aca981",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.countplot(x=\"TARGET\", data=app_train)\n",
    "plt.title('Balance of target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f19737",
   "metadata": {},
   "source": [
    "The target column is now balanced, this will allow the models to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d4d8e",
   "metadata": {},
   "source": [
    "## Days Employed feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3fd69",
   "metadata": {},
   "source": [
    "### Informations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b999543",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['DAYS_EMPLOYED'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693ce5e",
   "metadata": {},
   "source": [
    "### Minimum and maximum values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = abs(app_train['DAYS_EMPLOYED'].max())\n",
    "if mini > 365:\n",
    "    print(\"Days employed min :\", mini/365, \"years\" )\n",
    "else:\n",
    "    print(\"Days employed min :\", mini, \"days\" )\n",
    "    \n",
    "maxi = abs(app_train['DAYS_EMPLOYED'].min())\n",
    "print(\"Days employed max :\", maxi/365, \"years\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0635d9",
   "metadata": {},
   "source": [
    "We can see an anomaly : the biggest 'Days Employed' value is around 1000 years !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61f283",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=app_train['DAYS_EMPLOYED'])\n",
    "plt.title('Boxplot of Days Employed before cleaning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864b378",
   "metadata": {},
   "source": [
    "### Removing anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f37cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train.drop(app_train.index[(app_train[\"DAYS_EMPLOYED\"] > 12000)], axis=0, inplace=True)\n",
    "app_test.drop(app_test.index[(app_test[\"DAYS_EMPLOYED\"] > 12000)], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240570fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=abs(app_train['DAYS_EMPLOYED']))\n",
    "plt.title('Boxplot of Days Employed after cleaning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59601e5a",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e884753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlations = app_train.corr()['TARGET'].sort_values()\n",
    "print('Most Positive Correlations:\\n')\n",
    "print(correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n')\n",
    "print(correlations.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa9477",
   "metadata": {},
   "source": [
    "# Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdf = app_train.copy()\n",
    "Xdf.drop('TARGET', axis = 1, inplace = True)\n",
    "X_boruta = Xdf\n",
    "\n",
    "y = app_train[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147ea52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(\n",
    "    n_jobs=-1,\n",
    "    max_depth=5\n",
    ")\n",
    "\n",
    "boruta = bp(\n",
    "    estimator=forest,\n",
    "    n_estimators=20,\n",
    "    max_iter=100 # numbers of trials\n",
    ")\n",
    "\n",
    "boruta.fit(np.array(X_boruta), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to keep\n",
    "green_area = X_boruta.columns[boruta.support_].to_list()\n",
    "blue_area = X_boruta.columns[boruta.support_weak_].to_list()\n",
    "print(\"features in the green area\", green_area)\n",
    "print(\"features in the blue area\", blue_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d2761",
   "metadata": {},
   "source": [
    "# Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9cf560",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = green_area + blue_area\n",
    "X = X_boruta[features]\n",
    "app_test = app_test[features]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended test sizes for crossvalidation : [20, 25, 30]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd601eb9",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd3852",
   "metadata": {},
   "source": [
    "## Kneighbors - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 5),\n",
    "              'metric':['euclidean', 'manhattan']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28791c68",
   "metadata": {},
   "source": [
    "## Kneighbors - Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f69244",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(grid.best_score_, 2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1ed22",
   "metadata": {},
   "source": [
    "## Kneighbors - Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KN = grid.best_estimator_\n",
    "score = KN.score(X_test, y_test)\n",
    "print(\"KNeighbors classifier score :\" , round(score*100, 2) ,'%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336af58",
   "metadata": {},
   "source": [
    "# KNeighbors - Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbac9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KN.predict(X_test)\n",
    "print(\"Predictions:\\n\\n\", y_pred, '\\n')\n",
    "print(\"Real values:\\n\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b054b",
   "metadata": {},
   "source": [
    "## KNeighbors - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print('The confusion matrix shows us the number of :\\n')\n",
    "print('* True positives :', conf_matrix[0][0] ,'\\n')\n",
    "print('* True negatives :', conf_matrix[0][1],'\\n')\n",
    "print('* False positives:', conf_matrix[1][0] ,'\\n')\n",
    "print('* False negatives:', conf_matrix[1][1] ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ac968",
   "metadata": {},
   "source": [
    "## Kneighbors - Cross Validation Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c29324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score using cross validation:\", \n",
    "      round((cross_val_score(KN, X_train, y_train, cv=3, scoring='accuracy').mean())*100, 2), '%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b59874",
   "metadata": {},
   "source": [
    "## KNeighbors - Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb59e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, train_score, val_score = learning_curve(KN, \n",
    "                                           X_train, \n",
    "                                           y_train, \n",
    "                                           train_sizes = np.linspace(0.1, 1.0, 10),\n",
    "                                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053af909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb253f14",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb3eeb",
   "metadata": {},
   "source": [
    "Our problem is a very binary one : will someone repay their credit or won't they ? \n",
    "\n",
    "This is why we use logistic regression as our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d95828",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f25759",
   "metadata": {},
   "source": [
    "## LR - Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9762c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c6260",
   "metadata": {},
   "source": [
    "## LR - Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR.predict(X_test)\n",
    "print(\"Predictions:\\n\\n\", y_pred, '\\n')\n",
    "print(\"Real values:\\n\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ba094",
   "metadata": {},
   "source": [
    "## LR - Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0230e10c",
   "metadata": {},
   "source": [
    "### LR - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5acda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print('The confusion matrix shows us the number of :\\n')\n",
    "print('* True positives :', conf_matrix[0][0] ,'\\n')\n",
    "print('* True negatives :', conf_matrix[0][1],'\\n')\n",
    "print('* False positives:', conf_matrix[1][0] ,'\\n')\n",
    "print('* False negatives:', conf_matrix[1][1] ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7b485",
   "metadata": {},
   "source": [
    "### LR - Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da72ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986d67f",
   "metadata": {},
   "source": [
    "### LR - Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04edbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score:\", round((accuracy_score(y_test, y_pred)*100), 3), '%\\n')\n",
    "print(\"Accuracy score using cross validation:\", \n",
    "      round((cross_val_score(LR, X_train, y_train, cv=3, scoring='accuracy').mean())*100, 2), '%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a748f37",
   "metadata": {},
   "source": [
    "Model accuracy is a machine learning model performance metric that is defined as the ratio of true positives and true negatives to all positive and negative observations.\n",
    "\n",
    "The accuracy rate is great but it doesn’t tell us anything about the errors our machine learning models make on new data we haven’t seen before.\n",
    "\n",
    "Mathematically, it represents the ratio of the sum of true positive and true negatives out of all the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8851b9cf",
   "metadata": {},
   "source": [
    "### LR - Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01be8f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Precision score:\", round((precision_score(y_test, y_pred, average='macro')*100), 2), '%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278a463",
   "metadata": {},
   "source": [
    "The precision score is a useful measure of the success of prediction when the classes are very imbalanced.\n",
    "\n",
    "Mathematically, it represents the ratio of true positive to the sum of true positive and false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b860a",
   "metadata": {},
   "source": [
    "### LR - Recall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a766aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall score:\", round((metrics.recall_score(y_test, y_pred)*100), 2), '%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd0c58",
   "metadata": {},
   "source": [
    "Model recall score represents the model’s ability to correctly predict the positives out of actual positives. This is unlike precision which measures how many predictions made by models are actually positive out of all positive predictions made.\n",
    "\n",
    "Recall score is a useful measure of success of prediction when the classes are very imbalanced. \n",
    "\n",
    "Mathematically, it represents the ratio of true positive to the sum of true positive and false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff7b33",
   "metadata": {},
   "source": [
    "### LR - F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc203305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score:\", round((metrics.f1_score(y_test, y_pred))*100), 2, '%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb3732",
   "metadata": {},
   "source": [
    "F1-score is harmonic mean of precision and recall score and is used as a metrics in the scenarios where choosing either of precision or recall score can result in compromise in terms of model giving high false positives and false negatives respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3de05b",
   "metadata": {},
   "source": [
    "### LR - ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cee1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob = LR.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  prediction_prob)\n",
    "auc = metrics.roc_auc_score(y_test, prediction_prob)\n",
    "\n",
    "#create ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic curve\")\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d55fa",
   "metadata": {},
   "source": [
    "This curve displays the percentage of true positives predicted by the model as the prediction probability cutoff is lowered from 1 to 0.\n",
    "\n",
    "The higher the AUC (area under the curve), the more accurately our model is able to predict outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0630e",
   "metadata": {},
   "source": [
    "## LR - Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, train_score, val_score = learning_curve(LR, \n",
    "                                           X_train, \n",
    "                                           y_train,\n",
    "                                           train_sizes = np.linspace(0.1, 1.0, 10),\n",
    "                                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ae6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32b6f3",
   "metadata": {},
   "source": [
    "## Using our LR model on application test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test_LR = app_test.copy()\n",
    "# app_test_LR['TARGET'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56168de7",
   "metadata": {},
   "source": [
    "Application test doesn't have a TARGET column. \n",
    "\n",
    "That's why after the prediction, we can not see if our model finds the right value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884752c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = LR.predict(app_test_LR)\n",
    "app_test_LR['TARGET'] = y_pred_test.astype(int)\n",
    "print(app_test_LR['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e55d7",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fa6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='gini')\n",
    "DT.fit(X_train, y_train)\n",
    "plt.figure(figsize=(20,20))\n",
    "tree.plot_tree(DT)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d81ac6",
   "metadata": {},
   "source": [
    "## DT - Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0535d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DT.predict(X_test)\n",
    "print(\"Predictions:\\n\\n\", y_pred, '\\n')\n",
    "print(\"Real values:\\n\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86b0f9",
   "metadata": {},
   "source": [
    "## DT - Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60741bd",
   "metadata": {},
   "source": [
    "### DT - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print('The confusion matrix shows us the number of :\\n')\n",
    "print('* True positives :', conf_matrix[0][0] ,'\\n')\n",
    "print('* True negatives :', conf_matrix[0][1],'\\n')\n",
    "print('* False positives:', conf_matrix[1][0] ,'\\n')\n",
    "print('* False negatives:', conf_matrix[1][1] ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80f209",
   "metadata": {},
   "source": [
    "### DT - Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1729ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2035ee",
   "metadata": {},
   "source": [
    "### DT - Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score:\", round((accuracy_score(y_test, y_pred)*100), 2), '%\\n')\n",
    "print(\"Accuracy score using cross validation:\", \n",
    "      round((cross_val_score(DT, X_train, y_train, cv=3, scoring='accuracy').mean())*100, 2), '%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb258c4",
   "metadata": {},
   "source": [
    "## DT - Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, train_score, val_score = learning_curve(DT, \n",
    "                                           X_train, \n",
    "                                           y_train,\n",
    "                                           train_sizes = np.linspace(0.1, 1.0, 10),\n",
    "                                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62baa27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbfd72",
   "metadata": {},
   "source": [
    "## Using our DT model on application test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test_DT = app_test.copy()\n",
    "# app_test_DT['TARGET'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f386da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = DT.predict(app_test_DT)\n",
    "app_test_DT['TARGET'] = y_pred_test.astype(int)\n",
    "print(app_test_DT['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c144b95",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8aa652",
   "metadata": {},
   "source": [
    "## RF - Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF.predict(X_test)\n",
    "print(\"Predictions:\\n\\n\", y_pred, '\\n')\n",
    "print(\"Real values:\\n\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84acda25",
   "metadata": {},
   "source": [
    "## RF - Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd699a46",
   "metadata": {},
   "source": [
    "### RF - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbbe919",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print('The confusion matrix shows us the number of :\\n')\n",
    "print('* True positives :', conf_matrix[0][0] ,'\\n')\n",
    "print('* True negatives :', conf_matrix[0][1],'\\n')\n",
    "print('* False positives:', conf_matrix[1][0] ,'\\n')\n",
    "print('* False negatives:', conf_matrix[1][1] ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a4435",
   "metadata": {},
   "source": [
    "### RF - Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report:\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d0413",
   "metadata": {},
   "source": [
    "### RF -  Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score:\", round((accuracy_score(y_test, y_pred)*100), 2), '%\\n')\n",
    "print(\"Accuracy score using cross validation:\", \n",
    "      round((cross_val_score(RF, X_train, y_train, cv=3, scoring='accuracy').mean())*100, 2), '%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbdff4",
   "metadata": {},
   "source": [
    "## RF - Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, train_score, val_score = learning_curve(RF, \n",
    "                                           X_train, \n",
    "                                           y_train,\n",
    "                                           train_sizes = np.linspace(0.1, 1.0, 10),\n",
    "                                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6feaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e69df",
   "metadata": {},
   "source": [
    "## Using our RF model on application test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2287f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test_RF = app_test.copy()\n",
    "#app_test_RF['TARGET'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f95215",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = RF.predict(app_test_RF)\n",
    "app_test_RF['TARGET'] = y_pred_test.astype(int)\n",
    "print(app_test_RF['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930046da",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031fc9b2",
   "metadata": {},
   "source": [
    "## XGBoost - Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "XGBst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07102b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "XGBst.dump_model('dump.raw.txt')\n",
    "f = open('dump.raw.txt', 'r')\n",
    "print(f.read())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce5d657",
   "metadata": {},
   "source": [
    "## XGBoost - Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_predictions = XGBst.predict(dtest)\n",
    "y_pred = np.asarray([np.argmax(line) for line in probs_predictions])\n",
    "print(\"Predictions:\\n\\n\", y_pred, '\\n')\n",
    "print(\"Real values:\\n\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b2ce8",
   "metadata": {},
   "source": [
    "## XGBoost - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d889a54",
   "metadata": {},
   "source": [
    "### XGBoost - Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aefa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report:\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35707e4",
   "metadata": {},
   "source": [
    "### XGBoost - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print('The confusion matrix shows us the number of :\\n')\n",
    "print('* True positives :', conf_matrix[0][0] ,'\\n')\n",
    "print('* True negatives :', conf_matrix[0][1],'\\n')\n",
    "print('* False positives:', conf_matrix[1][0] ,'\\n')\n",
    "print('* False negatives:', conf_matrix[1][1] ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504a5c5",
   "metadata": {},
   "source": [
    "# Comparing models predictions on application test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_target = app_test_LR['TARGET'] \n",
    "DT_target = app_test_DT['TARGET']\n",
    "RF_target = app_test_RF['TARGET']\n",
    "\n",
    "one_dif = LR_target.compare(DT_target)\n",
    "two_dif = LR_target.compare(RF_target)\n",
    "three_dif = DT_target.compare(RF_target)\n",
    "\n",
    "print('Difference between LR and DT on app_test:\\nNumber of differences:', len(one_dif), '\\n', one_dif)\n",
    "print('Difference between LR and RF on app_test:\\nNumber of differences:', len(two_dif), '\\n', two_dif)\n",
    "print('Difference between DT and RF on app_test:\\nNumber of differences:', len(three_dif), '\\n', three_dif)\n",
    "\n",
    "if DT_target.equals(RF_target):\n",
    "    print(\"Decision Tree and Random Forest found the same target values on application test\")\n",
    "\n",
    "if LR_target.equals(DT_target):\n",
    "    if LR_target.equals(RF_target):\n",
    "        print(\"All three models found the same target values on application test.\")\n",
    "else: \n",
    "    print(\"All three models did not find the same target values on application test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8947d35",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d051e49",
   "metadata": {},
   "source": [
    "The data given was very unbalanced, we had to use undersampling to balance it to get accurate models.\n",
    "As the bank, if the model predicts too many true positives, this is not an issue. The bank would not give the loan to someone who could have repaid it. This isn't so great for the clients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
